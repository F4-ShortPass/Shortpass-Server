"""
ì˜¤ë‹µë…¸íŠ¸ í”¼ë“œë°± ë£¨í”„ POC í…ŒìŠ¤íŠ¸
Reflexion íŒ¨í„´ì„ í™œìš©í•œ Self-Improving AI Agent ê²€ì¦
"""
import asyncio
import sys
import os

# Add server directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from openai import AsyncOpenAI
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from db.database import Base
from models.feedback_memory import FeedbackMemory
from services.feedback.feedback_manager import FeedbackManager
from core.config import settings


async def test_feedback_poc():
    """POC ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""

    print("=" * 80)
    print("ğŸ§ª Feedback Loop POC Test - Reflexion Pattern")
    print("=" * 80)

    # 1. DB ì—°ê²° ë° í…Œì´ë¸” ìƒì„±
    print("\n[Step 1] Database Setup")
    print("-" * 80)

    engine = create_engine(settings.DATABASE_URL, echo=False)

    # pgvector extension í™•ì¸
    with engine.connect() as conn:
        result = conn.execute(text("SELECT * FROM pg_extension WHERE extname = 'vector'"))
        if result.fetchone():
            print("âœ“ pgvector extension is enabled")
        else:
            print("âœ— pgvector extension not found!")
            print("  Run: CREATE EXTENSION IF NOT EXISTS vector;")
            return

    # í…Œì´ë¸” ìƒì„±
    print("Creating feedback_memory table...")
    Base.metadata.create_all(bind=engine, tables=[FeedbackMemory.__table__])
    print("âœ“ Table created successfully")

    # Session ìƒì„±
    SessionLocal = sessionmaker(bind=engine)
    db = SessionLocal()

    # OpenAI í´ë¼ì´ì–¸íŠ¸
    openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

    # FeedbackManager ì´ˆê¸°í™”
    feedback_manager = FeedbackManager(db=db, openai_client=openai_client)


    # 2. ìƒ˜í”Œ í”¼ë“œë°± ì €ì¥
    print("\n[Step 2] Save Sample Feedback")
    print("-" * 80)

    sample_feedbacks = [
        {
            "job_category": "Sales",
            "competency_name": "interpersonal_skill",
            "ai_score": 70,
            "ai_reasoning": "ì§€ì›ìê°€ ê³µê²©ì ì¸ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ì¸ê´€ê³„ ì—­ëŸ‰ì´ ë¶€ì¡±í•´ ë³´ì„. ê³ ê°ê³¼ì˜ ì†Œí†µ ì‹œ ë¶€ë“œëŸ¬ìš´ ì ‘ê·¼ì´ í•„ìš”í•´ ë³´ì„.",
            "human_score": 90,
            "human_reasoning": "ì˜ì—… ì§ë¬´ì—ì„œëŠ” ê³µê²©ì„±ì´ ì•„ë‹ˆë¼ ì ê·¹ì„±ìœ¼ë¡œ í•´ì„í•´ì•¼ í•¨. ê³ ê° ì„¤ë“ë ¥ì´ ë›°ì–´ë‚˜ê³  ëª©í‘œ ì§€í–¥ì ì¸ íƒœë„ê°€ ìš°ìˆ˜í•¨.",
        },
        {
            "job_category": "Sales",
            "competency_name": "problem_solving",
            "ai_score": 60,
            "ai_reasoning": "ë¬¸ì œ í•´ê²° ì‚¬ë¡€ê°€ êµ¬ì²´ì ì´ì§€ ì•Šê³  ê²°ê³¼ ì¤‘ì‹¬ìœ¼ë¡œë§Œ ì„¤ëª…í•¨. ë¶„ì„ì  ì ‘ê·¼ì´ ë¶€ì¡±í•´ ë³´ì„.",
            "human_score": 85,
            "human_reasoning": "ì˜ì—… ì§ë¬´ì—ì„œëŠ” ë¹ ë¥¸ ì˜ì‚¬ê²°ì •ê³¼ ì‹¤í–‰ë ¥ì´ ë” ì¤‘ìš”í•¨. ë¶„ì„ë³´ë‹¤ëŠ” í–‰ë™ ì¤‘ì‹¬ì˜ ë¬¸ì œ í•´ê²° ë°©ì‹ì´ ì§ë¬´ì— ì í•©í•¨.",
        },
        {
            "job_category": "Engineering",
            "competency_name": "problem_solving",
            "ai_score": 85,
            "ai_reasoning": "ë…¼ë¦¬ì  ì‚¬ê³ ì™€ ì²´ê³„ì  ì ‘ê·¼ì´ ìš°ìˆ˜í•¨. ê¸°ìˆ ì  ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  í•´ê²°í•¨.",
            "human_score": 95,
            "human_reasoning": "ì•Œê³ ë¦¬ì¦˜ ìµœì í™”ì™€ ì‹œìŠ¤í…œ ì„¤ê³„ì—ì„œ íƒì›”í•œ ì—­ëŸ‰ ë³´ì„. ë‹¨ìˆœ ì ìˆ˜ë³´ë‹¤ ë” ë†’ê²Œ í‰ê°€í•´ì•¼ í•¨.",
        }
    ]

    saved_feedbacks = []
    for i, fb in enumerate(sample_feedbacks, 1):
        print(f"\n  Saving feedback {i}/{len(sample_feedbacks)}...")
        saved = await feedback_manager.save_feedback(
            evaluation_id=1000 + i,
            applicant_id=100 + i,
            **fb
        )
        saved_feedbacks.append(saved)
        print(f"    âœ“ ID: {saved.id}")
        print(f"    âœ“ Mistake: {saved.mistake_summary[:60]}...")
        print(f"    âœ“ Guideline: {saved.correction_guideline[:60]}...")

    print(f"\nâœ“ Saved {len(saved_feedbacks)} feedbacks to database")


    # 3. í”¼ë“œë°± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n[Step 3] Search Relevant Feedback (RAG)")
    print("-" * 80)

    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: ìƒˆë¡œìš´ Sales ì§€ì›ì í‰ê°€
    test_context = """
    ì§€ì›ìê°€ ì ê·¹ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë§íˆ¬ë¡œ ê³ ê° ì‘ëŒ€ ì‚¬ë¡€ë¥¼ ì„¤ëª…í•¨.
    "ì €ëŠ” ê³ ê°ì—ê²Œ ê°•ë ¥í•˜ê²Œ ì–´í•„í•˜ê³  ë¹ ë¥´ê²Œ ì˜ì‚¬ê²°ì •ì„ ìœ ë„í•©ë‹ˆë‹¤"ë¼ê³  ë‹µë³€.
    """

    print(f"\n  Query Context: {test_context.strip()}")
    print(f"  Job Category: Sales")
    print(f"  Competency: interpersonal_skill\n")

    relevant_feedbacks = await feedback_manager.get_relevant_feedback(
        job_category="Sales",
        competency_name="interpersonal_skill",
        current_context=test_context,
        top_k=3,
        similarity_threshold=0.5  # 50% ìœ ì‚¬ë„
    )

    print(f"\n  Found {len(relevant_feedbacks)} relevant feedbacks:\n")
    for i, fb in enumerate(relevant_feedbacks, 1):
        print(f"  [{i}] Similarity: {fb['similarity']:.2%}")
        print(f"      Mistake: {fb['mistake_summary']}")
        print(f"      Guideline: {fb['correction_guideline'][:80]}...")
        print(f"      Score Change: {fb['ai_score']}ì  â†’ {fb['human_score']}ì \n")


    # 4. CompetencyAgent í†µí•© í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
    print("\n[Step 4] Simulate CompetencyAgent with Feedback Injection")
    print("-" * 80)

    print("\n  ğŸ”¹ Scenario: AIê°€ ê³¼ê±°ì™€ ìœ ì‚¬í•œ ì‹¤ìˆ˜ë¥¼ í•  ë»”í–ˆì§€ë§Œ, í”¼ë“œë°± ë•ë¶„ì— ë°©ì§€ë¨\n")

    # ê³¼ê±° ì‹¤ìˆ˜: "ê³µê²©ì  ë§íˆ¬" â†’ ë‚®ì€ ì ìˆ˜
    print("  [Before Feedback Loop]")
    print("    AI Judgment: ì§€ì›ìê°€ ê³µê²©ì  â†’ 70ì ")
    print("    Problem: ì˜ì—… íŠ¹ì„±ì„ ê³ ë ¤í•˜ì§€ ëª»í•¨\n")

    # í”¼ë“œë°± ì£¼ì… í›„
    print("  [After Feedback Loop - with Reflexion]")
    if relevant_feedbacks:
        print(f"    âœ“ {len(relevant_feedbacks)}ê°œì˜ ìœ ì‚¬ í”¼ë“œë°± ë°œê²¬!")
        print(f"    âœ“ í”„ë¡¬í”„íŠ¸ì— êµì • ì§€ì¹¨ ì£¼ì…:")
        for fb in relevant_feedbacks[:1]:  # ì²« ë²ˆì§¸ë§Œ ì¶œë ¥
            print(f"      '{fb['correction_guideline']}'")
        print(f"\n    â†’ AIê°€ ì´ì œëŠ” 'ì ê·¹ì„±'ìœ¼ë¡œ ì¬í•´ì„í•  ê°€ëŠ¥ì„± â†‘")
        print(f"    â†’ ì˜ˆìƒ ì ìˆ˜: 85~90ì  (ê³¼ê±° Human Score ì°¸ê³ )")

    print("\n  ğŸ¯ Result: AIê°€ ê³¼ê±° ì‹¤ìˆ˜ë¥¼ í•™ìŠµí•˜ì—¬ ë™ì¼í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•¨!")


    # 5. í†µê³„ í™•ì¸
    print("\n[Step 5] Feedback Statistics")
    print("-" * 80)

    from sqlalchemy import func

    total = db.query(func.count(FeedbackMemory.id)).scalar()
    print(f"\n  Total Feedbacks: {total}")

    by_competency = db.query(
        FeedbackMemory.competency_name,
        func.count(FeedbackMemory.id).label('count')
    ).group_by(FeedbackMemory.competency_name).all()

    print(f"\n  By Competency:")
    for item in by_competency:
        print(f"    - {item.competency_name}: {item.count}")

    by_job = db.query(
        FeedbackMemory.job_category,
        func.count(FeedbackMemory.id).label('count')
    ).group_by(FeedbackMemory.job_category).all()

    print(f"\n  By Job Category:")
    for item in by_job:
        print(f"    - {item.job_category}: {item.count}")


    # ì •ë¦¬
    db.close()

    print("\n" + "=" * 80)
    print("âœ… POC Test Completed Successfully!")
    print("=" * 80)
    print("\nğŸ“Œ Next Steps:")
    print("  1. Frontend: CandidateEvaluation í˜ì´ì§€ì— 'ì ìˆ˜ ìˆ˜ì •' UI ì¶”ê°€")
    print("  2. API Integration: ì ìˆ˜ ìˆ˜ì • ì‹œ POST /api/v1/feedback/ í˜¸ì¶œ")
    print("  3. Agent Integration: evaluate_all_competenciesì— use_feedback=True ì „ë‹¬")
    print("  4. Production: ì‹¤ì œ í‰ê°€ íŒŒì´í”„ë¼ì¸ì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
    print("\nğŸ’¡ Expected Benefits:")
    print("  - AIê°€ ì“¸ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§ (Self-Evolving System)")
    print("  - HRì˜ ë„ë©”ì¸ ì§€ì‹ì´ ì‹œìŠ¤í…œì— ì¶•ì ë¨")
    print("  - ë™ì¼ ì‹¤ìˆ˜ ë°˜ë³µ ë°©ì§€ â†’ í‰ê°€ ì •í™•ë„ í–¥ìƒ")
    print()


if __name__ == "__main__":
    asyncio.run(test_feedback_poc())
