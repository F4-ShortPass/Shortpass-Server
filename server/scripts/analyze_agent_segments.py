"""
Agentê°€ ì‚¬ìš©í•œ Segment ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ëª©ì :
- OpenAI API í• ë‹¹ëŸ‰ ë¬¸ì œë¡œ ì„ë² ë”© ëŒ€ì‹  ê¸°ì¡´ Agent ë¡œê·¸ ë¶„ì„
- ì—­ëŸ‰ë³„ë¡œ ì–´ë–¤ segmentë¥¼ ì„ íƒí–ˆëŠ”ì§€ íŒ¨í„´ íŒŒì•…
- RAG ë„ì… ì‹œ ì˜ˆìƒ íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜

ë°ì´í„°:
- stage1_evidence.json (Agent í‰ê°€ ê²°ê³¼)
- transcript_jiwon_101.json (ë©´ì ‘ ëŒ€í™”)
"""
import os
import sys
import json
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Set
from datetime import datetime

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))


COMPETENCY_DISPLAY_NAMES = {
    "achievement_motivation": "ì„±ì·¨/ë™ê¸° ì—­ëŸ‰",
    "growth_potential": "ì„±ì¥ ì ì¬ë ¥",
    "interpersonal_skill": "ëŒ€ì¸ê´€ê³„ ì—­ëŸ‰",
    "organizational_fit": "ì¡°ì§ ì í•©ì„±",
    "problem_solving": "ë¬¸ì œ í•´ê²°",
    "customer_journey_marketing": "ê³ ê° ì—¬ì • ë§ˆì¼€íŒ…",
    "md_data_analysis": "MD ë°ì´í„° ë¶„ì„",
    "seasonal_strategy_kpi": "ì‹œì¦Œ ì „ëµ KPI",
    "stakeholder_collaboration": "ì´í•´ê´€ê³„ì í˜‘ì—…",
    "value_chain_optimization": "ê°€ì¹˜ì‚¬ìŠ¬ ìµœì í™”",
}


def analyze_agent_segment_usage(stage1_evidence: Dict, transcript: Dict) -> Dict:
    """
    Agentê°€ ì‚¬ìš©í•œ segment ë¶„ì„

    Returns:
        {
            "competency_name": {
                "segments_used": [1, 3, 5, ...],
                "segment_count": int,
                "evidence_count": int,
                "score": float,
                "segment_details": [...]
            }
        }
    """

    analysis = {}

    # Transcript segment ë§¤í•‘
    segments_by_id = {}
    for seg in transcript.get("segments", []):
        seg_id = seg["segment_id"]
        segments_by_id[seg_id] = {
            "segment_id": seg_id,
            "segment_order": seg.get("segment_order"),
            "question": seg.get("question_text", ""),
            "answer": seg.get("answer_text", ""),
            "turn_type": seg.get("turn_type"),
            "interviewer_name": seg.get("interviewer_name"),
        }

    # ì—­ëŸ‰ë³„ ë¶„ì„
    for comp_name, comp_data in stage1_evidence.items():
        if not isinstance(comp_data, dict):
            continue

        if comp_name not in COMPETENCY_DISPLAY_NAMES:
            continue

        # perspectivesì—ì„œ evidence_details ì¶”ì¶œ
        perspectives = comp_data.get("perspectives", {})
        evidence_details = perspectives.get("evidence_details", [])

        # Segment IDs ì¶”ì¶œ
        segments_used = set()
        segment_details = []

        for ev in evidence_details:
            seg_id = ev.get("segment_id")
            if seg_id and seg_id in segments_by_id:
                segments_used.add(seg_id)

                seg_info = segments_by_id[seg_id]
                segment_details.append({
                    "segment_id": seg_id,
                    "segment_order": seg_info["segment_order"],
                    "question": seg_info["question"][:80],
                    "answer": seg_info["answer"][:120],
                    "relevance_note": ev.get("relevance_note", ""),
                    "impact": ev.get("impact", ""),
                })

        analysis[comp_name] = {
            "segments_used": sorted(list(segments_used)),
            "segment_count": len(segments_used),
            "evidence_count": len(evidence_details),
            "score": comp_data.get("overall_score", 0),
            "confidence": comp_data.get("confidence", {}),
            "segment_details": segment_details
        }

    return analysis


def calculate_segment_overlap(analysis: Dict) -> Dict:
    """ì—­ëŸ‰ ê°„ segment ì¤‘ë³µ ë¶„ì„"""

    # Segmentë³„ë¡œ ì‚¬ìš©í•œ ì—­ëŸ‰ ë§¤í•‘
    segment_to_competencies = defaultdict(set)

    for comp_name, comp_analysis in analysis.items():
        for seg_id in comp_analysis["segments_used"]:
            segment_to_competencies[seg_id].add(comp_name)

    # ì¤‘ë³µë„ ê³„ì‚°
    overlap_stats = {
        "total_unique_segments": len(segment_to_competencies),
        "segments_by_usage_count": defaultdict(list),
        "highly_shared_segments": []  # 3ê°œ ì´ìƒ ì—­ëŸ‰ì—ì„œ ì‚¬ìš©
    }

    for seg_id, competencies in segment_to_competencies.items():
        usage_count = len(competencies)
        overlap_stats["segments_by_usage_count"][usage_count].append({
            "segment_id": seg_id,
            "competencies": sorted(list(competencies)),
            "usage_count": usage_count
        })

        if usage_count >= 3:
            overlap_stats["highly_shared_segments"].append({
                "segment_id": seg_id,
                "competencies": sorted(list(competencies)),
                "usage_count": usage_count
            })

    return overlap_stats


def simulate_rag_effect(analysis: Dict, transcript: Dict) -> Dict:
    """
    RAG ë„ì… ì‹œ ì˜ˆìƒ íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜

    ê°€ì •:
    - RAGëŠ” ì—­ëŸ‰ë³„ë¡œ ê´€ë ¨ì„± ë†’ì€ Top 5-8 segmentsë§Œ ì„ íƒ
    - AgentëŠ” ì „ì²´ transcriptë¥¼ ë°›ì•„ì„œ í‰ê°€
    """

    total_segments = len(transcript.get("segments", []))

    simulation = {
        "current_approach": {
            "method": "ì „ì²´ Transcriptë¥¼ 10ê°œ Agentì—ê²Œ ì „ì†¡",
            "tokens_per_agent": total_segments * 300,  # segmentë‹¹ í‰ê·  300 tokens
            "total_tokens": total_segments * 300 * 10,
            "cost_estimate_usd": (total_segments * 300 * 10) / 1000 * 0.005  # GPT-4o input
        },
        "rag_approach": {
            "method": "ì—­ëŸ‰ë³„ Top 5-8 segmentsë§Œ ì„ íƒ",
            "avg_segments_per_agent": 0,
            "tokens_per_agent": 0,
            "total_tokens": 0,
            "cost_estimate_usd": 0,
            "savings_rate": 0
        }
    }

    # ì—­ëŸ‰ë³„ í‰ê·  segment ì‚¬ìš©ëŸ‰
    total_segments_used = sum(comp["segment_count"] for comp in analysis.values())
    avg_segments = total_segments_used / len(analysis)

    simulation["rag_approach"]["avg_segments_per_agent"] = avg_segments
    simulation["rag_approach"]["tokens_per_agent"] = int(avg_segments * 300)
    simulation["rag_approach"]["total_tokens"] = int(avg_segments * 300 * 10)
    simulation["rag_approach"]["cost_estimate_usd"] = (avg_segments * 300 * 10) / 1000 * 0.005

    # ì ˆê°ë¥ 
    current_cost = simulation["current_approach"]["cost_estimate_usd"]
    rag_cost = simulation["rag_approach"]["cost_estimate_usd"]
    savings_rate = (current_cost - rag_cost) / current_cost if current_cost > 0 else 0

    simulation["rag_approach"]["savings_rate"] = savings_rate

    return simulation


def main():
    """ë©”ì¸ ì‹¤í–‰"""

    print("\n" + "="*80)
    print("  Agent Segment ì‚¬ìš© íŒ¨í„´ ë¶„ì„")
    print("="*80)

    # ë°ì´í„° ë¡œë“œ
    transcript_path = Path(__file__).parent.parent / "test_data" / "transcript_jiwon_101.json"
    evaluation_result_path = Path(__file__).parent.parent / "test_data" / "evaluation_result_jiwon_test.json"

    print(f"\n  ë°ì´í„° ë¡œë“œ:")
    print(f"  - Transcript: {transcript_path}")
    print(f"  - Evaluation Result: {evaluation_result_path}")

    with open(transcript_path, "r", encoding="utf-8") as f:
        transcript = json.load(f)

    with open(evaluation_result_path, "r", encoding="utf-8") as f:
        evaluation_result = json.load(f)

    stage1_evidence = evaluation_result.get("competency_results", {})

    print(f"  - Transcript: {len(transcript['segments'])}ê°œ segment")
    print(f"  - í‰ê°€ ì—­ëŸ‰: {len([k for k in stage1_evidence.keys() if k in COMPETENCY_DISPLAY_NAMES])}ê°œ")


    # Step 1: Agent segment ì‚¬ìš© ë¶„ì„
    print("\n" + "="*80)
    print("[Step 1] ì—­ëŸ‰ë³„ Segment ì‚¬ìš© íŒ¨í„´")
    print("="*80)

    analysis = analyze_agent_segment_usage(stage1_evidence, transcript)

    for comp_name, comp_analysis in analysis.items():
        comp_display = COMPETENCY_DISPLAY_NAMES.get(comp_name, comp_name)

        print(f"\n[{comp_display}]")
        print(f"  ì‚¬ìš© segments: {comp_analysis['segments_used']} ({comp_analysis['segment_count']}ê°œ)")
        print(f"  í‰ê°€ ì ìˆ˜: {comp_analysis['score']}ì ")

        # ìƒìœ„ 3ê°œ segment ìƒì„¸
        if comp_analysis['segment_details']:
            print(f"  ì£¼ìš” ê·¼ê±°:")
            for detail in comp_analysis['segment_details'][:3]:
                print(f"    â€¢ Segment {detail['segment_id']}: {detail['question'][:50]}...")
                print(f"      â†’ {detail['answer'][:60]}...")


    # Step 2: Segment ì¤‘ë³µë„ ë¶„ì„
    print("\n" + "="*80)
    print("[Step 2] Segment ì¤‘ë³µ ì‚¬ìš© ë¶„ì„")
    print("="*80)

    overlap_stats = calculate_segment_overlap(analysis)

    print(f"\n  ì´ ì‚¬ìš©ëœ ê³ ìœ  Segment: {overlap_stats['total_unique_segments']}ê°œ")
    print(f"  (ì „ì²´ {len(transcript['segments'])}ê°œ ì¤‘ {overlap_stats['total_unique_segments']}ê°œ ì‚¬ìš©)")

    print(f"\n  Segment ì‚¬ìš© ë¹ˆë„:")
    for usage_count in sorted(overlap_stats['segments_by_usage_count'].keys(), reverse=True):
        segments = overlap_stats['segments_by_usage_count'][usage_count]
        print(f"    {usage_count}ê°œ ì—­ëŸ‰ì—ì„œ ì‚¬ìš©: {len(segments)}ê°œ segment")

    if overlap_stats['highly_shared_segments']:
        print(f"\n  âš ï¸  3ê°œ ì´ìƒ ì—­ëŸ‰ì—ì„œ ê³µìœ ë˜ëŠ” Segment ({len(overlap_stats['highly_shared_segments'])}ê°œ):")
        for seg_info in overlap_stats['highly_shared_segments'][:5]:
            comp_names = [COMPETENCY_DISPLAY_NAMES.get(c, c) for c in seg_info['competencies']]
            print(f"    â€¢ Segment {seg_info['segment_id']}: {seg_info['usage_count']}ê°œ ì—­ëŸ‰")
            print(f"      â†’ {', '.join(comp_names)}")


    # Step 3: RAG íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜
    print("\n" + "="*80)
    print("[Step 3] RAG ë„ì… ì‹œ ì˜ˆìƒ íš¨ê³¼")
    print("="*80)

    simulation = simulate_rag_effect(analysis, transcript)

    print(f"\n  [í˜„ì¬ ë°©ì‹]")
    print(f"  - ë°©ë²•: {simulation['current_approach']['method']}")
    print(f"  - Agentë‹¹ tokens: {simulation['current_approach']['tokens_per_agent']:,}")
    print(f"  - ì´ tokens: {simulation['current_approach']['total_tokens']:,}")
    print(f"  - ì˜ˆìƒ ë¹„ìš©: ${simulation['current_approach']['cost_estimate_usd']:.4f}")

    print(f"\n  [RAG ë°©ì‹]")
    print(f"  - ë°©ë²•: {simulation['rag_approach']['method']}")
    print(f"  - Agentë‹¹ í‰ê·  segments: {simulation['rag_approach']['avg_segments_per_agent']:.1f}ê°œ")
    print(f"  - Agentë‹¹ tokens: {simulation['rag_approach']['tokens_per_agent']:,}")
    print(f"  - ì´ tokens: {simulation['rag_approach']['total_tokens']:,}")
    print(f"  - ì˜ˆìƒ ë¹„ìš©: ${simulation['rag_approach']['cost_estimate_usd']:.4f}")

    savings_rate = simulation['rag_approach']['savings_rate']
    print(f"\n  âœ… ì˜ˆìƒ ì ˆê°:")
    print(f"     Token: {savings_rate*100:.1f}% ì ˆê°")
    print(f"     ë¹„ìš©: ${simulation['current_approach']['cost_estimate_usd'] - simulation['rag_approach']['cost_estimate_usd']:.4f} ì ˆê°")


    # Step 4: RAG ë„ì… ì œì•ˆ
    print("\n" + "="*80)
    print("[Step 4] RAG ë„ì… ë¶„ì„ ê²°ê³¼")
    print("="*80)

    print(f"\n  ğŸ“Š í˜„í™© ë¶„ì„:")
    print(f"     - ì „ì²´ Segment: {len(transcript['segments'])}ê°œ")
    print(f"     - Agentê°€ ì‹¤ì œ ì‚¬ìš©í•œ í‰ê·  Segment: {simulation['rag_approach']['avg_segments_per_agent']:.1f}ê°œ")
    print(f"     - ì‚¬ìš©ë¥ : {simulation['rag_approach']['avg_segments_per_agent'] / len(transcript['segments']) * 100:.1f}%")

    print(f"\n  ğŸ’¡ ì¸ì‚¬ì´íŠ¸:")
    print(f"     1. AgentëŠ” ì „ì²´ì˜ {simulation['rag_approach']['avg_segments_per_agent'] / len(transcript['segments']) * 100:.1f}%ë§Œ ì‹¤ì œë¡œ ì‚¬ìš©")
    print(f"     2. ë‚˜ë¨¸ì§€ {100 - simulation['rag_approach']['avg_segments_per_agent'] / len(transcript['segments']) * 100:.1f}%ëŠ” ë…¸ì´ì¦ˆ")
    print(f"     3. RAGë¡œ ê´€ë ¨ segmentë§Œ ì„ ë³„í•˜ë©´ {savings_rate*100:.1f}% ì ˆê° ê°€ëŠ¥")

    print(f"\n  âœ… ê²°ë¡ :")
    if savings_rate >= 0.5:
        print(f"     RAG ë„ì… **ê°•ë ¥ ì¶”ì²œ** (ë¹„ìš© {savings_rate*100:.1f}% ì ˆê° + ì •í™•ë„ í–¥ìƒ ê¸°ëŒ€)")
    elif savings_rate >= 0.3:
        print(f"     RAG ë„ì… ì¶”ì²œ (ë¹„ìš© {savings_rate*100:.1f}% ì ˆê°)")
    else:
        print(f"     RAG íš¨ê³¼ ì œí•œì  (ë¹„ìš© {savings_rate*100:.1f}% ì ˆê°)")


    # ê²°ê³¼ ì €ì¥
    output_path = Path(__file__).parent.parent / "test_data" / "agent_segment_analysis.json"

    output_data = {
        "timestamp": datetime.now().isoformat(),
        "transcript_file": "transcript_jiwon_101.json",
        "total_segments": len(transcript["segments"]),
        "competency_analysis": analysis,
        "overlap_stats": {
            "total_unique_segments": overlap_stats["total_unique_segments"],
            "usage_distribution": {
                str(k): len(v) for k, v in overlap_stats["segments_by_usage_count"].items()
            },
            "highly_shared_count": len(overlap_stats["highly_shared_segments"])
        },
        "simulation": simulation
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\n  ê²°ê³¼ ì €ì¥: {output_path}")

    print("\n" + "="*80)
    print("  ë¶„ì„ ì™„ë£Œ!")
    print("="*80)


if __name__ == "__main__":
    main()
