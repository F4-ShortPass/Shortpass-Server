"""
RAG ì„ë² ë”© íš¨ê³¼ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ëª©ì :
- ê¸°ì¡´ í‰ê°€ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ segment layerì—ì„œ RAG íš¨ê³¼ ê²€ì¦
- Segmentë³„ ì„ë² ë”© ìƒì„±
- ì—­ëŸ‰ë³„ RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- ê´€ë ¨ì„± ì ìˆ˜ ë¹„êµ

ë°ì´í„°:
- transcript_jiwon_101.json (ë©´ì ‘ ëŒ€í™”)
- evaluation_result_101.json (ê¸°ì¡´ í‰ê°€ ê²°ê³¼)
"""
import os
import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple
import numpy as np

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from dotenv import load_dotenv
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path, override=True)

from openai import AsyncOpenAI


# ì—­ëŸ‰ë³„ ê²€ìƒ‰ ì¿¼ë¦¬ ì •ì˜
COMPETENCY_SEARCH_QUERIES = {
    # Common Competencies (5ê°œ)
    "achievement_motivation": "ëª©í‘œ ì„¤ì •, ìë°œì  ì‹œì‘, ë‚´ì  ë™ê¸°, ë¿Œë“¯í•œ ê²½í—˜, ì„±ì·¨ ìš•êµ¬, ë„ì „ ì¶”êµ¬, í”„ë¡œì íŠ¸ ì™„ìˆ˜, ìê¸°ì£¼ë„ì ",
    "growth_potential": "í•™ìŠµ ê²½í—˜, ì‹¤íŒ¨ë¡œë¶€í„° ë°°ì›€, ìƒˆë¡œìš´ ê¸°ìˆ  ìŠµë“, ìê¸°ê³„ë°œ, í”¼ë“œë°± ìˆ˜ìš©, ì„±ì¥ ë§ˆì¸ë“œ, ê°œì„  ë…¸ë ¥",
    "interpersonal_skill": "íŒ€ì›Œí¬, í˜‘ì—… ê²½í—˜, ê°ˆë“± í•´ê²°, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ê´€ê³„ í˜•ì„±, ê³µê° ëŠ¥ë ¥, ì„¤ë“ë ¥, ë¦¬ìŠ¤ë‹",
    "organizational_fit": "ì¡°ì§ ë¬¸í™”, ê°€ì¹˜ê´€, ì—…ë¬´ ìŠ¤íƒ€ì¼, íŒ€ ì ì‘, íšŒì‚¬ ì„ íƒ ì´ìœ , ì—…ë¬´ í™˜ê²½, ì¡°ì§ ìƒí™œ",
    "problem_solving": "ë¬¸ì œ í•´ê²° ì‚¬ë¡€, ë…¼ë¦¬ì  ì‚¬ê³ , ì°½ì˜ì  ì ‘ê·¼, ë¶„ì„ ëŠ¥ë ¥, ë³µì¡í•œ ìƒí™© ëŒ€ì²˜, ì˜ì‚¬ê²°ì •",

    # Job Competencies (5ê°œ)
    "customer_journey_marketing": "ê³ ê° ì—¬ì •, VMD, ë§ˆì¼€íŒ… ì „ëµ, ë¸Œëœë“œ ê²½í—˜, ê³ ê° í–‰ë™, ë§¤ì¥ ìš´ì˜, ì‹œê°ì  ë¨¸ì²œë‹¤ì´ì§•",
    "md_data_analysis": "ë°ì´í„° ë¶„ì„, íŠ¸ë Œë“œ ë¶„ì„, ë§¤ì¶œ ë¶„ì„, ìƒí’ˆ ê¸°íš, íŒë§¤ ë°ì´í„°, ì¬ê³  ë¶„ì„, SKU ê´€ë¦¬, í”¼ë²— í…Œì´ë¸”",
    "seasonal_strategy_kpi": "ì‹œì¦Œ ì „ëµ, KPI ì„¤ì •, ëª©í‘œ ë‹¬ì„±, ì „ëµ ìˆ˜ë¦½, ì„±ê³¼ ì§€í‘œ, ë¹„ì¦ˆë‹ˆìŠ¤ ê³„íš, ì‹¤í–‰ë ¥",
    "stakeholder_collaboration": "ì´í•´ê´€ê³„ì í˜‘ì—…, ë¶€ì„œê°„ í˜‘ë ¥, í˜‘ìƒ, ì¡°ìœ¨, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, íŒŒíŠ¸ë„ˆì‹­",
    "value_chain_optimization": "ì†Œì‹±, ìƒì‚°, ìœ í†µ, ê³µê¸‰ë§, ì›ê°€ ì ˆê°, íš¨ìœ¨í™”, ë¬¼ë¥˜, ë²¤ë” ê´€ë¦¬",
}

COMPETENCY_DISPLAY_NAMES = {
    "achievement_motivation": "ì„±ì·¨/ë™ê¸° ì—­ëŸ‰",
    "growth_potential": "ì„±ì¥ ì ì¬ë ¥",
    "interpersonal_skill": "ëŒ€ì¸ê´€ê³„ ì—­ëŸ‰",
    "organizational_fit": "ì¡°ì§ ì í•©ì„±",
    "problem_solving": "ë¬¸ì œ í•´ê²°",
    "customer_journey_marketing": "ê³ ê° ì—¬ì • ë§ˆì¼€íŒ…",
    "md_data_analysis": "MD ë°ì´í„° ë¶„ì„",
    "seasonal_strategy_kpi": "ì‹œì¦Œ ì „ëµ KPI",
    "stakeholder_collaboration": "ì´í•´ê´€ê³„ì í˜‘ì—…",
    "value_chain_optimization": "ê°€ì¹˜ì‚¬ìŠ¬ ìµœì í™”",
}


def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    return float(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))


async def generate_embeddings(
    client: AsyncOpenAI,
    texts: List[str]
) -> List[List[float]]:
    """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""

    print(f"  ì„ë² ë”© ìƒì„± ì¤‘... ({len(texts)}ê°œ í…ìŠ¤íŠ¸)")

    response = await client.embeddings.create(
        model="text-embedding-3-small",
        input=texts
    )

    embeddings = [item.embedding for item in response.data]
    print(f"  âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embeddings[0])})")

    return embeddings


async def create_segment_embeddings(
    client: AsyncOpenAI,
    transcript: Dict
) -> Dict[int, Dict]:
    """
    Segmentë³„ ì„ë² ë”© ìƒì„±

    Returns:
        {
            segment_id: {
                "segment_id": int,
                "question": str,
                "answer": str,
                "combined_text": str,
                "embedding": List[float],
                "metadata": {...}
            }
        }
    """

    print("\n" + "="*80)
    print("[Step 1] Segment ì„ë² ë”© ìƒì„±")
    print("="*80)

    segments = transcript.get("segments", [])

    # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì§ˆë¬¸ + ë‹µë³€)
    segment_texts = []
    segment_metadata = []

    for seg in segments:
        segment_id = seg["segment_id"]
        question = seg.get("question_text", "")
        answer = seg.get("answer_text", "")

        # ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê²°í•© (ë” ë‚˜ì€ ì˜ë¯¸ í‘œí˜„)
        combined_text = f"ì§ˆë¬¸: {question}\në‹µë³€: {answer}"

        segment_texts.append(combined_text)
        segment_metadata.append({
            "segment_id": segment_id,
            "segment_order": seg.get("segment_order"),
            "question": question,
            "answer": answer,
            "combined_text": combined_text,
            "turn_type": seg.get("turn_type"),
            "interviewer_name": seg.get("interviewer_name"),
        })

    # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    embeddings = await generate_embeddings(client, segment_texts)

    # ê²°ê³¼ ì¡°í•©
    segment_embeddings = {}
    for metadata, embedding in zip(segment_metadata, embeddings):
        segment_id = metadata["segment_id"]
        segment_embeddings[segment_id] = {
            **metadata,
            "embedding": embedding
        }

    print(f"\n  ì´ {len(segment_embeddings)}ê°œ Segment ì„ë² ë”© ìƒì„± ì™„ë£Œ")

    return segment_embeddings


async def test_rag_search(
    client: AsyncOpenAI,
    competency_name: str,
    segment_embeddings: Dict[int, Dict],
    top_k: int = 5
) -> List[Dict]:
    """
    íŠ¹ì • ì—­ëŸ‰ì— ëŒ€í•œ RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸

    Returns:
        [
            {
                "segment_id": int,
                "similarity": float,
                "question": str,
                "answer": str,
                "rank": int
            }
        ]
    """

    # 1. ì—­ëŸ‰ë³„ ê²€ìƒ‰ ì¿¼ë¦¬
    search_query = COMPETENCY_SEARCH_QUERIES.get(
        competency_name,
        f"{competency_name} ê´€ë ¨ í–‰ë™ ì‚¬ë¡€"
    )

    # 2. ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = await generate_embeddings(client, [search_query])
    query_vector = query_embedding[0]

    # 3. ëª¨ë“  segmentì™€ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    for segment_id, seg_data in segment_embeddings.items():
        seg_embedding = seg_data["embedding"]
        similarity = cosine_similarity(query_vector, seg_embedding)

        similarities.append({
            "segment_id": segment_id,
            "segment_order": seg_data["segment_order"],
            "similarity": similarity,
            "question": seg_data["question"],
            "answer": seg_data["answer"],
            "turn_type": seg_data["turn_type"],
            "interviewer_name": seg_data["interviewer_name"],
        })

    # 4. ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    similarities.sort(key=lambda x: x["similarity"], reverse=True)

    # 5. Top-K ë°˜í™˜
    top_results = []
    for rank, result in enumerate(similarities[:top_k], 1):
        top_results.append({
            **result,
            "rank": rank
        })

    return top_results


async def compare_with_agent_evaluation(
    rag_results: Dict[str, List[Dict]],
    evaluation_result: Dict
) -> Dict:
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ì™€ Agent í‰ê°€ ê²°ê³¼ ë¹„êµ

    Args:
        rag_results: {competency_name: [top_k_segments]}
        evaluation_result: ê¸°ì¡´ í‰ê°€ ê²°ê³¼

    Returns:
        ë¹„êµ ë¶„ì„ ê²°ê³¼
    """

    print("\n" + "="*80)
    print("[Step 3] RAG vs Agent í‰ê°€ ë¹„êµ")
    print("="*80)

    comparison = {}

    competency_results = evaluation_result.get("competency_results", {})

    for comp_name, rag_top_k in rag_results.items():
        comp_result = competency_results.get(comp_name, {})

        # Agentê°€ ì‚¬ìš©í•œ evidence_details ì¶”ì¶œ
        perspectives = comp_result.get("perspectives", {})
        evidence_details = perspectives.get("evidence_details", [])

        agent_segment_ids = set()
        for ev in evidence_details:
            seg_id = ev.get("segment_id")
            if seg_id:
                agent_segment_ids.add(seg_id)

        # RAG Top-K segment IDs
        rag_segment_ids = set([r["segment_id"] for r in rag_top_k])

        # êµì§‘í•© (ê²¹ì¹˜ëŠ” segment)
        overlap = agent_segment_ids.intersection(rag_segment_ids)

        # ë¹„êµ ê²°ê³¼
        comparison[comp_name] = {
            "agent_segments": sorted(list(agent_segment_ids)),
            "rag_top_k_segments": sorted(list(rag_segment_ids)),
            "overlap_segments": sorted(list(overlap)),
            "overlap_count": len(overlap),
            "overlap_rate": len(overlap) / len(agent_segment_ids) if agent_segment_ids else 0.0,
            "agent_score": comp_result.get("overall_score"),
            "rag_top_k": rag_top_k[:3]  # ìƒìœ„ 3ê°œë§Œ ì €ì¥
        }

    return comparison


async def main():
    """ë©”ì¸ ì‹¤í–‰"""

    print("\n" + "="*80)
    print("  RAG ì„ë² ë”© íš¨ê³¼ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("="*80)

    # ë°ì´í„° ë¡œë“œ
    data_dir = Path(__file__).parent.parent / "test_data"
    transcript_path = data_dir / "transcript_jiwon_101.json"
    evaluation_result_path = data_dir / "evaluation_result_101.json"

    with open(transcript_path, "r", encoding="utf-8") as f:
        transcript = json.load(f)

    with open(evaluation_result_path, "r", encoding="utf-8") as f:
        evaluation_result = json.load(f)

    print(f"\n  ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    print(f"  - Transcript: {len(transcript['segments'])}ê°œ segment")
    print(f"  - í‰ê°€ ê²°ê³¼: {len(evaluation_result.get('competency_results', {}))}ê°œ ì—­ëŸ‰")

    # OpenAI í´ë¼ì´ì–¸íŠ¸
    client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))


    # Step 1: Segment ì„ë² ë”© ìƒì„±
    segment_embeddings = await create_segment_embeddings(client, transcript)


    # Step 2: ì—­ëŸ‰ë³„ RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n" + "="*80)
    print("[Step 2] ì—­ëŸ‰ë³„ RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("="*80)

    rag_results = {}

    # 10ê°œ ì—­ëŸ‰ í…ŒìŠ¤íŠ¸
    competencies_to_test = list(COMPETENCY_SEARCH_QUERIES.keys())

    for comp_name in competencies_to_test:
        comp_display = COMPETENCY_DISPLAY_NAMES.get(comp_name, comp_name)
        print(f"\n[{comp_display}]")
        print(f"  ê²€ìƒ‰ ì¿¼ë¦¬: {COMPETENCY_SEARCH_QUERIES[comp_name][:60]}...")

        top_results = await test_rag_search(
            client,
            comp_name,
            segment_embeddings,
            top_k=8
        )

        rag_results[comp_name] = top_results

        # ìƒìœ„ 3ê°œ ì¶œë ¥
        print(f"  Top 3 segments:")
        for result in top_results[:3]:
            print(f"    {result['rank']}. Segment {result['segment_id']} (ìœ ì‚¬ë„: {result['similarity']:.3f})")
            print(f"       Q: {result['question'][:60]}...")
            print(f"       A: {result['answer'][:80]}...")


    # Step 3: Agent í‰ê°€ì™€ ë¹„êµ
    comparison = await compare_with_agent_evaluation(rag_results, evaluation_result)


    # Step 4: ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
    print("\n" + "="*80)
    print("[Step 4] RAG íš¨ê³¼ ë¶„ì„")
    print("="*80)

    total_overlap = 0
    total_agent_segments = 0

    print("\nì—­ëŸ‰ë³„ RAG vs Agent ë¹„êµ:")
    print("-"*80)

    for comp_name, comp_comparison in comparison.items():
        comp_display = COMPETENCY_DISPLAY_NAMES.get(comp_name, comp_name)

        agent_segs = comp_comparison["agent_segments"]
        rag_segs = comp_comparison["rag_top_k_segments"]
        overlap = comp_comparison["overlap_segments"]
        overlap_rate = comp_comparison["overlap_rate"]

        total_overlap += len(overlap)
        total_agent_segments += len(agent_segs)

        print(f"\n[{comp_display}]")
        print(f"  Agent ì‚¬ìš© segments: {agent_segs} ({len(agent_segs)}ê°œ)")
        print(f"  RAG Top-8 segments: {rag_segs[:8]} ({len(rag_segs)}ê°œ)")
        print(f"  ê²¹ì¹˜ëŠ” segments: {overlap} ({len(overlap)}ê°œ)")
        print(f"  âœ“ ì¼ì¹˜ìœ¨: {overlap_rate*100:.1f}%")

        if overlap_rate >= 0.7:
            print(f"  â†’ í‰ê°€: ğŸŸ¢ RAGê°€ Agent íŒë‹¨ê³¼ 70% ì´ìƒ ì¼ì¹˜")
        elif overlap_rate >= 0.5:
            print(f"  â†’ í‰ê°€: ğŸŸ¡ RAGê°€ Agent íŒë‹¨ê³¼ 50% ì´ìƒ ì¼ì¹˜")
        else:
            print(f"  â†’ í‰ê°€: ğŸ”´ RAGê°€ Agent íŒë‹¨ê³¼ 50% ë¯¸ë§Œ ì¼ì¹˜ (ê°œì„  í•„ìš”)")

    # ì „ì²´ í‰ê· 
    avg_overlap_rate = total_overlap / total_agent_segments if total_agent_segments > 0 else 0.0

    print("\n" + "-"*80)
    print(f"[ì „ì²´ í‰ê· ]")
    print(f"  ì „ì²´ ì¼ì¹˜ìœ¨: {avg_overlap_rate*100:.1f}%")
    print(f"  ì´ Agent segments: {total_agent_segments}ê°œ")
    print(f"  ì´ ê²¹ì¹˜ëŠ” segments: {total_overlap}ê°œ")

    if avg_overlap_rate >= 0.6:
        print(f"\n  âœ… ê²°ë¡ : RAGê°€ Agent íŒë‹¨ì„ {avg_overlap_rate*100:.1f}% ì¬í˜„ ê°€ëŠ¥!")
        print(f"         â†’ RAG ë„ì… ì‹œ í‰ê°€ ì •í™•ë„ ìœ ì§€ ê°€ëŠ¥")
    else:
        print(f"\n  âš ï¸  ê²°ë¡ : RAG ì¼ì¹˜ìœ¨ {avg_overlap_rate*100:.1f}% (ê°œì„  í•„ìš”)")
        print(f"         â†’ ê²€ìƒ‰ ì¿¼ë¦¬ ë˜ëŠ” Top-K ì¡°ì • í•„ìš”")


    # ê²°ê³¼ ì €ì¥
    output_path = data_dir / "rag_test_result.json"

    output_data = {
        "timestamp": datetime.now().isoformat(),
        "transcript_file": "transcript_jiwon_101.json",
        "evaluation_file": "evaluation_result_101.json",
        "segment_count": len(segment_embeddings),
        "competencies_tested": len(competencies_to_test),
        "avg_overlap_rate": avg_overlap_rate,
        "comparison": comparison,
        "rag_results": {
            comp_name: [
                {
                    "segment_id": r["segment_id"],
                    "similarity": r["similarity"],
                    "rank": r["rank"],
                    "question": r["question"][:100],
                    "answer": r["answer"][:150]
                }
                for r in results
            ]
            for comp_name, results in rag_results.items()
        }
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\n  ê²°ê³¼ ì €ì¥: {output_path}")

    print("\n" + "="*80)
    print("  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)


if __name__ == "__main__":
    asyncio.run(main())
