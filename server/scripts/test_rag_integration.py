"""
RAG í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ëª©ì :
- CompetencyAgent RAG í†µí•© ê²€ì¦
- ì„ë² ë”© ìƒì„± ë° RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- í† í° ì ˆê° íš¨ê³¼ ì¸¡ì •

ì‹¤í–‰ ë°©ë²•:
    python scripts/test_rag_integration.py
"""
import os
import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from dotenv import load_dotenv
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path, override=True)

from openai import AsyncOpenAI
from sqlalchemy.orm import Session

from db.database import get_db
from models.interview import SessionTranscript, InterviewSession, InterviewStatus
from services.rag_embedding_service import generate_and_save_transcript_embeddings
from ai.agents.competency_agent import CompetencyAgent


async def create_test_transcripts(db: Session, transcript: dict) -> int:
    """
    í…ŒìŠ¤íŠ¸ìš© ë©´ì ‘ ì„¸ì…˜ ë° transcript ìƒì„±

    Returns:
        session_id: ìƒì„±ëœ ì„¸ì…˜ ID
    """
    print("\n" + "="*80)
    print("[Step 1] í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±")
    print("="*80)

    # 1. í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ìƒì„±
    session = InterviewSession(
        applicant_id=101,
        company_id=1,
        status=InterviewStatus.COMPLETED
    )
    db.add(session)
    db.commit()
    db.refresh(session)

    print(f"\n  âœ“ í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ìƒì„±: session_id={session.id}")

    # 2. Transcript segmentsë¥¼ SessionTranscriptë¡œ ë³€í™˜
    segments = transcript.get("segments", [])

    for seg in segments:
        # ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê²°í•©
        combined_text = f"ì§ˆë¬¸: {seg.get('question_text', '')}\\në‹µë³€: {seg.get('answer_text', '')}"

        st = SessionTranscript(
            session_id=session.id,
            persona_instance_id=None,
            turn=seg.get("segment_order"),
            text=combined_text,
            meta_json={
                "segment_id": seg.get("segment_id"),
                "interviewer_name": seg.get("interviewer_name"),
                "turn_type": seg.get("turn_type")
            }
        )
        db.add(st)

    db.commit()

    print(f"  âœ“ {len(segments)}ê°œ transcript ìƒì„±")

    return session.id


async def test_rag_evaluation(
    db: Session,
    session_id: int,
    transcript: dict
):
    """
    RAG ê¸°ë°˜ í‰ê°€ í…ŒìŠ¤íŠ¸
    """
    print("\n" + "="*80)
    print("[Step 3] RAG í‰ê°€ í…ŒìŠ¤íŠ¸")
    print("="*80)

    # OpenAI í´ë¼ì´ì–¸íŠ¸
    client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # 1. RAG ì—†ì´ í‰ê°€
    print("\n[1] RAG ë¹„í™œì„±í™” í‰ê°€:")
    agent_no_rag = CompetencyAgent(
        openai_client=client,
        use_rag=False
    )

    # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (í…ŒìŠ¤íŠ¸ìš©)
    test_prompt = f"""
ë‹¤ìŒ ë©´ì ‘ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ 'ë¬¸ì œ í•´ê²° ëŠ¥ë ¥'ì„ í‰ê°€í•˜ì„¸ìš”.

ë©´ì ‘ ëŒ€í™”:
{json.dumps(transcript.get('segments', [])[:3], ensure_ascii=False, indent=2)}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "overall_score": 75,
    "strengths": ["êµ¬ì²´ì  ë¶„ì„ í”„ë ˆì„ì›Œí¬ ì‚¬ìš©"],
    "weaknesses": ["ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë¯¸í¡"],
    "key_observations": ["ë°ì´í„° ê¸°ë°˜ ì ‘ê·¼"],
    "perspectives": {{
        "evidence_reasoning": "êµ¬ì¡°ì  ì‚¬ê³  ëŠ¥ë ¥ ìš°ìˆ˜",
        "evidence_details": []
    }},
    "confidence": {{
        "overall_confidence": 0.8
    }}
}}
"""

    try:
        result_no_rag = await agent_no_rag.evaluate(
            competency_name="problem_solving",
            competency_display_name="ë¬¸ì œí•´ê²°ë ¥",
            competency_category="common",
            prompt=test_prompt,
            transcript=transcript
        )
        print(f"  âœ“ í‰ê°€ ì™„ë£Œ: {result_no_rag.get('overall_score')}ì ")
    except Exception as e:
        print(f"  âœ— í‰ê°€ ì‹¤íŒ¨: {e}")
        result_no_rag = None


    # 2. RAG í™œì„±í™” í‰ê°€
    print("\n[2] RAG í™œì„±í™” í‰ê°€:")
    agent_with_rag = CompetencyAgent(
        openai_client=client,
        use_rag=True,
        rag_top_k=5,
        db_session=db
    )

    try:
        result_with_rag = await agent_with_rag.evaluate(
            competency_name="problem_solving",
            competency_display_name="ë¬¸ì œí•´ê²°ë ¥",
            competency_category="common",
            prompt=test_prompt,
            transcript=transcript,
            session_id=session_id
        )
        print(f"  âœ“ í‰ê°€ ì™„ë£Œ: {result_with_rag.get('overall_score')}ì ")

        # RAG ë©”íƒ€ë°ì´í„° í™•ì¸
        rag_metadata = transcript.get("rag_metadata", {})
        if rag_metadata:
            print(f"  ğŸ“Š RAG í†µê³„:")
            print(f"    - ì›ë³¸ segments: {rag_metadata.get('original_segment_count')}")
            print(f"    - í•„í„° segments: {rag_metadata.get('filtered_segment_count')}")
            print(f"    - í† í° ì ˆê°ë¥ : {rag_metadata.get('token_reduction_rate', 0)*100:.1f}%")

    except Exception as e:
        print(f"  âœ— í‰ê°€ ì‹¤íŒ¨: {e}")
        result_with_rag = None


    # 3. ê²°ê³¼ ë¹„êµ
    print("\n[3] ê²°ê³¼ ë¹„êµ:")
    if result_no_rag and result_with_rag:
        print(f"  RAG ì—†ì´: {result_no_rag.get('overall_score')}ì ")
        print(f"  RAG ì‚¬ìš©: {result_with_rag.get('overall_score')}ì ")
        print(f"  ì ìˆ˜ ì°¨ì´: {abs(result_no_rag.get('overall_score', 0) - result_with_rag.get('overall_score', 0))}ì ")


async def main():
    """ë©”ì¸ ì‹¤í–‰"""

    print("\n" + "="*80)
    print("  RAG í†µí•© í…ŒìŠ¤íŠ¸")
    print("="*80)

    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    transcript_path = Path(__file__).parent.parent / "test_data" / "transcript_jiwon_101.json"

    with open(transcript_path, "r", encoding="utf-8") as f:
        transcript = json.load(f)

    print(f"\n  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {transcript_path}")
    print(f"  ì´ segments: {len(transcript.get('segments', []))}ê°œ")


    # 2. DB ì„¸ì…˜
    db_generator = get_db()
    db = next(db_generator)

    try:
        # 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        session_id = await create_test_transcripts(db, transcript)


        # 4. ì„ë² ë”© ìƒì„±
        print("\n" + "="*80)
        print("[Step 2] ì„ë² ë”© ìƒì„±")
        print("="*80)

        embedding_result = await generate_and_save_transcript_embeddings(
            db=db,
            session_id=session_id,
            force_regenerate=True
        )

        print(f"\n  âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ:")
        print(f"    - ì´ transcript: {embedding_result['total_transcripts']}ê°œ")
        print(f"    - ìƒì„±ëœ embedding: {embedding_result['embeddings_generated']}ê°œ")


        # 5. RAG í‰ê°€ í…ŒìŠ¤íŠ¸
        await test_rag_evaluation(db, session_id, transcript)


        print("\n" + "="*80)
        print("  âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*80)

    finally:
        # Cleanup
        db.close()


if __name__ == "__main__":
    asyncio.run(main())
